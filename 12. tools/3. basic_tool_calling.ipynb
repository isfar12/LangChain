{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "195401b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import HumanMessage\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e16377f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing command:\n",
      " whoami\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_community\\tools\\shell\\tool.py:33: UserWarning: The shell tool has no safeguards by default. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'isfar-ideapad\\\\lenovo\\r\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.tools import ShellTool\n",
    "\n",
    "shell=ShellTool()\n",
    "shell.invoke(\"whoami\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d01b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'url': 'https://cloud.google.com/use-cases/langchain', 'content': '# What is LangChain?\\n\\nLangChain is a programming language platform that lets developers construct and connect models to access, transform, and share data seamlessly. It offers a powerful and versatile environment for model development, enabling the manipulation of data structures, model chaining, and the incorporation of external agents like LaMDA. [...] LangChain operates on the principle of modularity, decomposing language-based AI systems into reusable components. These components, known as \"chains,\" encapsulate specific functionalities, such as data retrieval, model interaction, and memory management. By assembling these chains in various configurations, developers can tailor LangChain to meet the unique requirements of their applications. [...] At its core, LangChain leverages a distributed architecture that enables efficient and scalable processing of language data. It employs a microservices-based design, where each chain runs as an independent service, facilitating flexible deployment and management. This architecture allows for seamless integration with external services, including LLMs and cloud-based data sources.\\n\\nLearn more about how you can use LangChain with VertexAI.\\n\\n## Key features of LangChain\\n\\n### Model interaction'}, {'url': 'https://www.geeksforgeeks.org/artificial-intelligence/introduction-to-langchain/', 'content': 'LangChain is an open-source framework designed to simplify the creation of applications using large language models (LLMs). It provides a standard interface for chains, many integrations with other tools, and end-to-end chains for common applications.\\n\\nLangChain allows AI developers to develop applications based on the combined Large Language Models (such as GPT-4) with external sources of computation and data. This framework comes with a package for both Python and JavaScript. [...] Applications of LangChain\\n-------------------------\\n\\nLangChain is a powerful tool that can be used to build a wide range of LLM-powered applications. It is simple to use and has a large user and contributor community. [...] ### Why is LangChain Important?\\n\\nLangChain helps manage complex workflows, making it easier to integrate LLMs into various applications like chatbots and document analysis. Key benefits include:\\n\\n   Modular Workflow: Simplifies chaining LLMs together for reusable and efficient workflows.\\n   Prompt Management: Offers tools for effective prompt engineering and memory handling.\\n   Ease of Integration: Streamlines the process of building LLM-powered applications.'}, {'url': 'https://en.wikipedia.org/wiki/LangChain', 'content': 'Image 5Free and open-source software portal\\n\\nLangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain\\'s use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.(\\n\\nHistory\\n-------\\n\\n[edit] [...] | LangChain |\\n| --- |\\n| Image 4: ðŸ¦œï¸ðŸ”—, the parrot and chain emojis |\\n| Developer(s) | Harrison Chase |\\n| Initial release | October 2022 |\\n|  |\\n| Stable release | 0.1.16( / 11 April 2024; 14 months ago(11 April 2024) |\\n|  |\\n| Repository \"Repository (version control)\") | github.com/langchain-ai/langchain |\\n| Written in | Python \"Python (programming language)\") and JavaScript |\\n| Type | Software framework for large language model application development |\\n| License | MIT License | [...] What links here\\n   Related changes\\n   Upload file\\n   Permanent link\\n   Page information\\n   Cite this page\\n   Get shortened URL\\n   Download QR code\\n   Expand all\\n   Edit interlanguage links\\n\\n Print/export \\n\\n   Download as PDF\\n   Printable version\\n\\n In other projects \\n\\n   Wikimedia Commons\\n   Wikidata item\\n\\nFrom Wikipedia, the free encyclopedia\\n\\nLanguage model application development framework'}, {'url': 'https://lakefs.io/blog/what-is-langchain-ml-architecture/', 'content': 'LangChain is an open-source framework that gives developers the tools they need to create applications using large language models (LLMs). In its essence, LangChain is a prompt orchestration tool that makes it easier for teams to connect various prompts interactively.\\n\\nLangChain began as an open source project, but as the GitHub stars piled up, it was quickly turned into a company led by Harrison Chase. [...] LangChain is one of the most useful frameworks for developers looking to create LLM-powered applications. It allows LLM models to create replies based on the most up-to-date data accessible online and simplifies the process of arranging vast volumes of data so that LLMs can quickly access it. [...] Once completed, you can start developing applications with LangChain. LangChain offers a number of tools and APIs that make it simple to link language models to external data sources, interact with their surroundings, and develop complicated applications.\\n\\nIt creates a workflow by chaining together a sequence of components called links. Each link in the chain does something specific, such as:'}, {'url': 'https://www.ibm.com/think/topics/langchain', 'content': 'LangChain is an open source orchestration framework for application development using large language models (LLMs). Available in both Python- and Javascript-based libraries, LangChainâ€™s tools and APIs simplify the process of building LLM-driven applications like chatbots and AI agents. [...] LangChain is essentially a library of abstractions for Python and Javascript, representing common steps and concepts necessary to work with language models. These modular componentsâ€”like functions and object classesâ€”serve as the building blocks of generative AI programs. They can be â€œ_chained_â€ together to create applications, minimizing the amount of code and fine understanding required to execute complex NLP tasks. Though LangChainâ€™s abstracted approach may limit the extent to which an expert [...] Getting started with LangChain\\n------------------------------\\n\\nLangChain is open source and free to use: source code isavailable for download on Github.\\n\\nLangChain can also be installed on Python with a simple pip command:_pip install langchain_. To install all LangChain dependencies (rather than only those you find necessary), you can run the command _pip install langchain[all]_.'}]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TAVILY_API_KEY\"] = \"secret\"\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "tavily = TavilySearchResults(max_results=5)\n",
    "print(tavily.run(\"What is LangChain?\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e34ee43",
   "metadata": {},
   "source": [
    "# Create a Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82df69b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Given two numbers a and b, return their product.\"\"\"\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c2c63b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiply.invoke({\"a\": 2, \"b\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "174e677a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': {'title': 'A', 'type': 'integer'},\n",
       " 'b': {'title': 'B', 'type': 'integer'}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiply.args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7da0436",
   "metadata": {},
   "source": [
    "# Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1da0859a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "chat = ChatOllama(\n",
    "    model=\"llama3.2:latest\",\n",
    "    temperature=.5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85462c81",
   "metadata": {},
   "source": [
    "# Bind the tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6a0bb8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools=chat.bind_tools([multiply])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e885c43",
   "metadata": {},
   "source": [
    "# Testing if tools are called"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ae0aae7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'llama3.2:latest', 'created_at': '2025-08-09T16:32:15.3852056Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1513029400, 'load_duration': 56980000, 'prompt_eval_count': 175, 'prompt_eval_duration': 66530700, 'eval_count': 22, 'eval_duration': 1388455200, 'model_name': 'llama3.2:latest'}, id='run--038ff91e-9aa0-4cd2-ab74-ddcc070b2564-0', tool_calls=[{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': '5367109b-b895-4abd-9028-65b508d24ac8', 'type': 'tool_call'}], usage_metadata={'input_tokens': 175, 'output_tokens': 22, 'total_tokens': 197})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools.invoke(\"Can you multiply 2 and 3?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8411645",
   "metadata": {},
   "source": [
    "# Check Which tools were called"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "908f69c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'multiply',\n",
       "  'args': {'a': 2, 'b': 3},\n",
       "  'id': '8f26b3bb-27f8-4ef8-b283-8c8fe97eadb2',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_calls=llm_with_tools.invoke(\"Can you multiply 2 and 3?\").tool_calls\n",
    "tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cbed47",
   "metadata": {},
   "source": [
    "# Invoke the tool_message into Custom Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a0401e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolMessage(content='6', name='multiply', tool_call_id='8f26b3bb-27f8-4ef8-b283-8c8fe97eadb2')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiply.invoke(tool_calls[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff2eafb",
   "metadata": {},
   "source": [
    "# Combine all and create a full AI response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fe70bc",
   "metadata": {},
   "source": [
    "1. Create A Human message/ Prompt\n",
    "2. Invoke using LLM and return a AI message\n",
    "3. Add both message in the list\n",
    "4. Find the tool were called \n",
    "5. Invoke the tool using the tool message extracted from step 4\n",
    "6. Combine all the messge\n",
    "7. Send the list of messages to AI\n",
    "8. Print final result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "494e692d",
   "metadata": {},
   "outputs": [],
   "source": [
    "message=HumanMessage(\"What is the multiplication of 2 and 10?\")\n",
    "message=[message]\n",
    "llm_message=llm_with_tools.invoke(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "053dda23",
   "metadata": {},
   "outputs": [],
   "source": [
    "message.append(llm_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fe1c0a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is the multiplication of 2 and 10?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'llama3.2:latest', 'created_at': '2025-08-09T17:27:02.8126514Z', 'done': True, 'done_reason': 'stop', 'total_duration': 9157557700, 'load_duration': 2257430100, 'prompt_eval_count': 177, 'prompt_eval_duration': 5569765300, 'eval_count': 22, 'eval_duration': 1327185600, 'model_name': 'llama3.2:latest'}, id='run--17f8750d-880e-471c-98b1-91e80ca02b2e-0', tool_calls=[{'name': 'multiply', 'args': {'a': '2', 'b': '10'}, 'id': '241f3d87-f77a-4771-884d-2ecfef4a2e32', 'type': 'tool_call'}], usage_metadata={'input_tokens': 177, 'output_tokens': 22, 'total_tokens': 199})]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "89034cf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolMessage(content='20', name='multiply', tool_call_id='241f3d87-f77a-4771-884d-2ecfef4a2e32')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_calls=multiply.invoke(llm_message.tool_calls[0])\n",
    "tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "656b04ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "message.append(tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "634bfaca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is the multiplication of 2 and 10?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'llama3.2:latest', 'created_at': '2025-08-09T17:27:02.8126514Z', 'done': True, 'done_reason': 'stop', 'total_duration': 9157557700, 'load_duration': 2257430100, 'prompt_eval_count': 177, 'prompt_eval_duration': 5569765300, 'eval_count': 22, 'eval_duration': 1327185600, 'model_name': 'llama3.2:latest'}, id='run--17f8750d-880e-471c-98b1-91e80ca02b2e-0', tool_calls=[{'name': 'multiply', 'args': {'a': '2', 'b': '10'}, 'id': '241f3d87-f77a-4771-884d-2ecfef4a2e32', 'type': 'tool_call'}], usage_metadata={'input_tokens': 177, 'output_tokens': 22, 'total_tokens': 199}),\n",
       " ToolMessage(content='20', name='multiply', tool_call_id='241f3d87-f77a-4771-884d-2ecfef4a2e32')]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6587b9a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The result of multiplying 2 and 10 is 20.'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools.invoke(message).content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
